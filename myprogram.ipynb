{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1LVk5xr9tWf7lncM88wi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flashlight-byte/learngit/blob/main/myprogram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **人脸图像**\n"
      ],
      "metadata": {
        "id": "QMpZsaTn3nZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **挂载Googledrive并安装环境**"
      ],
      "metadata": {
        "id": "72TBlzWOAWZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # 将google硬盘挂载在/comtent/drive/目录上面"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "GCMc86WNZ-jT",
        "outputId": "ef9ec641-3625-40b2-a549-24ece3ac0151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1b8ab6f6d6a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 将google硬盘挂载在/comtent/drive/目录上面\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 128\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "id": "4eKNY5houBmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb36d996-abc5-4c7e-91f8-921108e42d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar 19 07:00:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /drive/MyDrive/essay/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPpVhRefx1Ic",
        "outputId": "2752fccb-40c3-4f8e-b146-fbe00156b91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/essay/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd #输出当前工作路径"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kofMRILHw9ca",
        "outputId": "1e83ce9f-3c33-4c4d-9d7a-b74f20f8750e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall pillow\n",
        "! pip install pillow==6.1.0"
      ],
      "metadata": {
        "id": "QvcNilfLs1hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall torchvision\n",
        "! pip install torchvision==0.4.0"
      ],
      "metadata": {
        "id": "sWxDYHTi_IZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBiDoPPgewPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df206b14-5324-42cd-eda7-1340d6bd902d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install torch==1.2.0\n",
        "! pip3 install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eWvkAdttbHj",
        "outputId": "80daab55-51cd-4939-f48e-e6a31f468a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall scipy\n",
        "! pip install scipy==1.2.0"
      ],
      "metadata": {
        "id": "bLoZ4fAbt85-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087e38b0-0780-4839-d9a8-c183019c86ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scipy 1.2.0\n",
            "Uninstalling scipy-1.2.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/scipy-1.2.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/scipy/*\n",
            "Proceed (y/n)? n\n",
            "Requirement already satisfied: scipy==1.2.0 in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.0) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python --version  # 查看python版本\n",
        "! nvcc --version # 查看cuda版本\n",
        "# ! pip list"
      ],
      "metadata": {
        "id": "MKka_ie7kKnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24df91aa-5990-47d0-d07e-f32e8a284078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! apt install p7zip-full #安装7.zip\n",
        "#! 7z x img_align_celeba.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRxmVO9z_6Uz",
        "outputId": "7c2da313-b879-4111-a3ad-acad91096b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **下载数据集并解压（手动）**"
      ],
      "metadata": {
        "id": "QUDC-jnl7TgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LearningToPaint\n",
        "# ! mkdir data\n",
        "%cd baseline/"
      ],
      "metadata": {
        "id": "RcDX10157p-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddeb52c8-45b6-4c4f-fa7d-1a532ded4f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'LearningToPaint'\n",
            "/content\n",
            "[Errno 2] No such file or directory: 'baseline/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf img_align_celeba 删除文件夹"
      ],
      "metadata": {
        "id": "85gvC2ABJTUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip img_align_celeba.zip"
      ],
      "metadata": {
        "id": "-UuDsvPQwakU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! rm img_align_celeba.zip #删除压缩文件\n",
        "# cd .. #返回上一个目录级别/essay"
      ],
      "metadata": {
        "id": "dXsFEu3ADxBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **导入需要的库**"
      ],
      "metadata": {
        "id": "X_ypdIk2AmNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import scipy.misc\n",
        "from io import BytesIO\n",
        "import tensorboardX as tb\n",
        "from tensorboardX.summary import Summary\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.weight_norm as weightNorm\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "import random\n",
        "import pickle as pickle\n",
        "from torch.optim import Adam, SGD\n",
        "from torch import autograd\n",
        "from torch.autograd import grad as torch_grad\n",
        "import argparse\n",
        "import time"
      ],
      "metadata": {
        "id": "I_2zAYlhAqyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **设置各部分**\n",
        "---"
      ],
      "metadata": {
        "id": "m80qmOHr_j4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Utils**"
      ],
      "metadata": {
        "id": "C8AB51e1ACYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "def prRed(prt): print(\"\\033[91m {}\\033[00m\" .format(prt))\n",
        "def prGreen(prt): print(\"\\033[92m {}\\033[00m\" .format(prt))\n",
        "def prYellow(prt): print(\"\\033[93m {}\\033[00m\" .format(prt))\n",
        "def prLightPurple(prt): print(\"\\033[94m {}\\033[00m\" .format(prt))\n",
        "def prPurple(prt): print(\"\\033[95m {}\\033[00m\" .format(prt))\n",
        "def prCyan(prt): print(\"\\033[96m {}\\033[00m\" .format(prt))\n",
        "def prLightGray(prt): print(\"\\033[97m {}\\033[00m\" .format(prt))\n",
        "def prBlack(prt): print(\"\\033[98m {}\\033[00m\" .format(prt))\n",
        "\n",
        "def to_numpy(var):\n",
        "    return var.cpu().data.numpy() if USE_CUDA else var.data.numpy()\n",
        "\n",
        "def to_tensor(ndarray, device):\n",
        "    return torch.tensor(ndarray, dtype=torch.float, device=device)\n",
        "\n",
        "def soft_update(target, source, tau):\n",
        "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
        "        target_param.data.copy_(\n",
        "            target_param.data * (1.0 - tau) + param.data * tau\n",
        "        )\n",
        "\n",
        "def hard_update(target, source):\n",
        "    for m1, m2 in zip(target.modules(), source.modules()):\n",
        "        m1._buffers = m2._buffers.copy()\n",
        "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
        "            target_param.data.copy_(param.data)\n",
        "\n",
        "def get_output_folder(parent_dir, env_name):\n",
        "    \"\"\"Return save folder.\n",
        "\n",
        "    Assumes folders in the parent_dir have suffix -run{run\n",
        "    number}. Finds the highest run number and sets the output folder\n",
        "    to that number + 1. This is just convenient so that if you run the\n",
        "    same script multiple times tensorboard can plot all of the results\n",
        "    on the same plots with different names.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    parent_dir: str\n",
        "      Path of the directory containing all experiment runs.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    parent_dir/run_dir\n",
        "      Path to this run's save directory.\n",
        "    \"\"\"\n",
        "    os.makedirs(parent_dir, exist_ok=True)\n",
        "    experiment_id = 0\n",
        "    for folder_name in os.listdir(parent_dir):\n",
        "        if not os.path.isdir(os.path.join(parent_dir, folder_name)):\n",
        "            continue\n",
        "        try:\n",
        "            folder_name = int(folder_name.split('-run')[-1])\n",
        "            if folder_name > experiment_id:\n",
        "                experiment_id = folder_name\n",
        "        except:\n",
        "            pass\n",
        "    experiment_id += 1\n",
        "\n",
        "    parent_dir = os.path.join(parent_dir, env_name)\n",
        "    parent_dir = parent_dir + '-run{}'.format(experiment_id)\n",
        "    os.makedirs(parent_dir, exist_ok=True)\n",
        "    return parent_dir\n"
      ],
      "metadata": {
        "id": "GItBu9WtAMGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorBoard(object):\n",
        "#TensorBoard用于提供机器学习工作流程期间所需的测量和可视化的工具\n",
        "    def __init__(self, model_dir):\n",
        "        self.summary_writer = tb.FileWriter(model_dir)\n",
        "\n",
        "    def add_image(self, tag, img, step):\n",
        "        summary = Summary()\n",
        "        bio = BytesIO()\n",
        "\n",
        "        if type(img) == str:\n",
        "            img = PIL.Image.open(img)\n",
        "        elif type(img) == PIL.Image.Image:\n",
        "            pass\n",
        "        else:\n",
        "            img = scipy.misc.toimage(img)\n",
        "\n",
        "        img.save(bio, format=\"png\")\n",
        "        image_summary = Summary.Image(encoded_image_string=bio.getvalue())\n",
        "        summary.value.add(tag=tag, image=image_summary)\n",
        "        self.summary_writer.add_summary(summary, global_step=step)\n",
        "\n",
        "    def add_scalar(self, tag, value, step):\n",
        "        summary = Summary(value=[Summary.Value(tag=tag, simple_value=value)])\n",
        "        self.summary_writer.add_summary(summary, global_step=step)\n"
      ],
      "metadata": {
        "id": "XU1wS3SzAHXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Renderer**"
      ],
      "metadata": {
        "id": "Qr05wQKyBKH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN(nn.Module): #全卷积网络\n",
        "    def __init__(self):\n",
        "        super(FCN, self).__init__()\n",
        "        self.fc1 = (nn.Linear(10, 512))\n",
        "        self.fc2 = (nn.Linear(512, 1024))\n",
        "        self.fc3 = (nn.Linear(1024, 2048))\n",
        "        self.fc4 = (nn.Linear(2048, 4096))\n",
        "        self.conv1 = (nn.Conv2d(16, 32, 3, 1, 1))\n",
        "        #torch.nn.Conv2d( in_channels , out_channels , kernel_size 3x3,\n",
        "        # stride=1 , 上下左右 padding=1)\n",
        "        self.conv2 = (nn.Conv2d(32, 32, 3, 1, 1))\n",
        "        self.conv3 = (nn.Conv2d(8, 16, 3, 1, 1))\n",
        "        self.conv4 = (nn.Conv2d(16, 16, 3, 1, 1))\n",
        "        self.conv5 = (nn.Conv2d(4, 8, 3, 1, 1))\n",
        "        self.conv6 = (nn.Conv2d(8, 4, 3, 1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
        "\n",
        "    def forward(self, x): # b * 10\n",
        "        x = F.relu(self.fc1(x)) #512\n",
        "        x = F.relu(self.fc2(x)) #1024\n",
        "        x = F.relu(self.fc3(x)) #2048\n",
        "        x = F.relu(self.fc4(x)) #4096\n",
        "        x = x.view(-1, 16, 16, 16)  #reshape b x16x16x16\n",
        "        x = F.relu(self.conv1(x))        # b x16x16x32\n",
        "        x = self.pixel_shuffle(self.conv2(x))  # b x16x16x32 (8x2x2)\n",
        "        #pixel_shuffle上采样的一种方法        b x32x32x8\n",
        "        # (*, C×r^2, H, W)(∗,C×r,H×r,W×r)\n",
        "        x = F.relu(self.conv3(x))        # b x32x32x16\n",
        "        x = self.pixel_shuffle(self.conv4(x))  # b x32x32x16 -> b x64x64x4\n",
        "        x = F.relu(self.conv5(x))        # b x64x64x8\n",
        "        x = self.pixel_shuffle(self.conv6(x))  # b x64x64x4 -> b x128x128x1\n",
        "        x = torch.sigmoid(x)\n",
        "        return 1 - x.view(-1, 128, 128)\n"
      ],
      "metadata": {
        "id": "1NCVh87tBNX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stroke_gen 笔画生成\n",
        "def normal(x, width):\n",
        "    return (int)(x * (width - 1) + 0.5)\n",
        "\n",
        "def draw(f, width=128):\n",
        "    x0, y0, x1, y1, x2, y2, z0, z2, w0, w2 = f\n",
        "    #x,y是点；z是thickness粗细；w是transparency透明度\n",
        "    #10维向量生成灰度笔画，agent把其他3维动作和灰度图相乘得到彩色图像\n",
        "    x1 = x0 + (x2 - x0) * x1\n",
        "    y1 = y0 + (y2 - y0) * y1\n",
        "    #其实这是对(x1, y1)的一个限制，我不希望agent使用陡峭拐角的曲线。\n",
        "    x0 = normal(x0, width * 2)\n",
        "    x1 = normal(x1, width * 2)\n",
        "    x2 = normal(x2, width * 2)\n",
        "    y0 = normal(y0, width * 2)\n",
        "    y1 = normal(y1, width * 2)\n",
        "    y2 = normal(y2, width * 2)\n",
        "    #这些操作应该是归一化 the floor division //\n",
        "    z0 = (int)(1 + z0 * width // 2)\n",
        "    z2 = (int)(1 + z2 * width // 2)\n",
        "    #定义画布大小 256x256\n",
        "    canvas = np.zeros([width * 2, width * 2]).astype('float32')\n",
        "    tmp = 1. / 100 #让t从0-1取值100次\n",
        "    for i in range(100):\n",
        "        t = i * tmp\n",
        "        x = (int)((1-t) * (1-t) * x0 + 2 * t * (1-t) * x1 + t * t * x2)\n",
        "        y = (int)((1-t) * (1-t) * y0 + 2 * t * (1-t) * y1 + t * t * y2)\n",
        "        z = (int)((1-t) * z0 + t * z2)\n",
        "        w = (1-t) * w0 + t * w2\n",
        "        cv2.circle(canvas, (y, x), z, w, -1)\n",
        "        #cv2.circle(image, center_coordinates, radius, color, thickness)\n",
        "    return 1 - cv2.resize(canvas, dsize=(width, width))\n",
        "    #变回原来大小，整个反色"
      ],
      "metadata": {
        "id": "tE1jhBqwBboM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Actor网络**"
      ],
      "metadata": {
        "id": "1_l34CQtMt5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#actor\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return (nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False))\n",
        "\n",
        "def cfg(depth):\n",
        "    depth_lst = [18, 34, 50, 101, 152]\n",
        "    assert (depth in depth_lst), \"Error : Resnet depth should be either 18, 34, 50, 101, 152\"\n",
        "    cf_dict = {\n",
        "        '18': (BasicBlock, [2,2,2,2]),\n",
        "        '34': (BasicBlock, [3,4,6,3]),\n",
        "        '50': (Bottleneck, [3,4,6,3]),\n",
        "        '101':(Bottleneck, [3,4,23,3]),\n",
        "        '152':(Bottleneck, [3,8,36,3]),\n",
        "    }\n",
        "\n",
        "    return cf_dict[str(depth)]\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                (nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = (nn.Conv2d(in_planes, planes, kernel_size=1, bias=False))\n",
        "        self.conv2 = (nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False))\n",
        "        self.conv3 = (nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False))\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                (nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_inputs, depth, num_outputs):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        block, num_blocks = cfg(depth)\n",
        "\n",
        "        self.conv1 = conv3x3(num_inputs, 64, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_outputs)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = F.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "c0YJCXUfB6KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **critic网络**"
      ],
      "metadata": {
        "id": "OPyWfDn_M6JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#critic\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return weightNorm(nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True))\n",
        "\n",
        "class TReLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TReLU, self).__init__()\n",
        "        self.alpha = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.alpha.data.fill_(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(x - self.alpha) + self.alpha\n",
        "        return x\n",
        "\n",
        "def cfg(depth):\n",
        "    depth_lst = [18, 34, 50, 101, 152]\n",
        "    assert (depth in depth_lst), \"Error : Resnet depth should be either 18, 34, 50, 101, 152\"\n",
        "    cf_dict = {\n",
        "        '18': (BasicBlock, [2,2,2,2]),\n",
        "        '34': (BasicBlock, [3,4,6,3]),\n",
        "        '50': (Bottleneck, [3,4,6,3]),\n",
        "        '101':(Bottleneck, [3,4,23,3]),\n",
        "        '152':(Bottleneck, [3,8,36,3]),\n",
        "    }\n",
        "\n",
        "    return cf_dict[str(depth)]\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                weightNorm(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True)),\n",
        "            )\n",
        "        self.relu_1 = TReLU()\n",
        "        self.relu_2 = TReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu_1(self.conv1(x))\n",
        "        out = self.conv2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = weightNorm(nn.Conv2d(in_planes, planes, kernel_size=1, bias=True))\n",
        "        self.conv2 = weightNorm(nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True))\n",
        "        self.conv3 = weightNorm(nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=True))\n",
        "        self.relu_1 = TReLU()\n",
        "        self.relu_2 = TReLU()\n",
        "        self.relu_3 = TReLU()\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                weightNorm(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True)),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu_1(self.conv1(x))\n",
        "        out = self.relu_2(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet_wobn(nn.Module):\n",
        "    def __init__(self, num_inputs, depth, num_outputs):\n",
        "        super(ResNet_wobn, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        block, num_blocks = cfg(depth)\n",
        "\n",
        "        self.conv1 = conv3x3(num_inputs, 64, 2)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_outputs)\n",
        "        self.relu_1 = TReLU()\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu_1(self.conv1(x))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = F.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9vdISElqCPV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluator**"
      ],
      "metadata": {
        "id": "mMQYQx__M-ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator(object):\n",
        "# evaluate(env, agent.select_action, debug=debug)\n",
        "    def __init__(self, args, writer):\n",
        "        self.validate_episodes = args.validate_episodes\n",
        "        self.max_step = args.max_step\n",
        "        self.env_batch = args.env_batch\n",
        "        self.writer = writer\n",
        "        self.log = 0\n",
        "\n",
        "    def __call__(self, env, policy, debug=False):\n",
        "        observation = None\n",
        "        for episode in range(self.validate_episodes):\n",
        "            # reset at the start of episode\n",
        "            observation = env.reset(test=True, episode=episode)\n",
        "            episode_steps = 0\n",
        "            episode_reward = 0.\n",
        "            assert observation is not None\n",
        "            # start episode\n",
        "            episode_reward = np.zeros(self.env_batch)\n",
        "            while (episode_steps < self.max_step or not self.max_step):\n",
        "                action = policy(observation)\n",
        "                observation, reward, done, (step_num) = env.step(action)\n",
        "                episode_reward += reward\n",
        "                episode_steps += 1\n",
        "                env.save_image(self.log, episode_steps)\n",
        "            dist = env.get_dist()\n",
        "            self.log += 1\n",
        "        return episode_reward, dist\n"
      ],
      "metadata": {
        "id": "2Q5q5FFaCiaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Repaly buffer**"
      ],
      "metadata": {
        "id": "T23jYgT3NDR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rpm\n",
        "\n",
        "class rpm(object):\n",
        "    # replay memory\n",
        "    def __init__(self, buffer_size):\n",
        "        self.buffer_size = buffer_size\n",
        "        self.buffer = []\n",
        "        self.index = 0\n",
        "\n",
        "    def append(self, obj):\n",
        "        if self.size() > self.buffer_size:\n",
        "            print('buffer size larger than set value, trimming...')\n",
        "            self.buffer = self.buffer[(self.size() - self.buffer_size):]\n",
        "        elif self.size() == self.buffer_size:\n",
        "            self.buffer[self.index] = obj\n",
        "            self.index += 1\n",
        "            self.index %= self.buffer_size\n",
        "        else:\n",
        "            self.buffer.append(obj)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def sample_batch(self, batch_size, device, only_state=False):\n",
        "        if self.size() < batch_size:\n",
        "            batch = random.sample(self.buffer, self.size())\n",
        "        else:\n",
        "            batch = random.sample(self.buffer, batch_size)\n",
        "\n",
        "        if only_state:\n",
        "            res = torch.stack(tuple(item[3] for item in batch), dim=0)\n",
        "            return res.to(device)\n",
        "        else:\n",
        "            item_count = 5\n",
        "            res = []\n",
        "            for i in range(5):\n",
        "                k = torch.stack(tuple(item[i] for item in batch), dim=0)\n",
        "                res.append(k.to(device))\n",
        "            return res[0], res[1], res[2], res[3], res[4]\n"
      ],
      "metadata": {
        "id": "mq2m0AIzDPtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **WGAN**"
      ],
      "metadata": {
        "id": "1GgNWLubNJMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dim = 128\n",
        "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
        "\n",
        "class TReLU(nn.Module):\n",
        "    def __init__(self):\n",
        "            super(TReLU, self).__init__()\n",
        "            self.alpha = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "            self.alpha.data.fill_(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(x - self.alpha) + self.alpha\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Discriminator, self).__init__()\n",
        "\n",
        "            self.conv0 = weightNorm(nn.Conv2d(6, 16, 5, 2, 2))\n",
        "            self.conv1 = weightNorm(nn.Conv2d(16, 32, 5, 2, 2))\n",
        "            self.conv2 = weightNorm(nn.Conv2d(32, 64, 5, 2, 2))\n",
        "            self.conv3 = weightNorm(nn.Conv2d(64, 128, 5, 2, 2))\n",
        "            self.conv4 = weightNorm(nn.Conv2d(128, 1, 5, 2, 2))\n",
        "            self.relu0 = TReLU()\n",
        "            self.relu1 = TReLU()\n",
        "            self.relu2 = TReLU()\n",
        "            self.relu3 = TReLU()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.conv0(x)\n",
        "            x = self.relu0(x)\n",
        "            x = self.conv1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.conv2(x)\n",
        "            x = self.relu2(x)\n",
        "            x = self.conv3(x)\n",
        "            x = self.relu3(x)\n",
        "            x = self.conv4(x)\n",
        "            x = F.avg_pool2d(x, 4)\n",
        "            x = x.view(-1, 1)\n",
        "            return x\n",
        "\n",
        "netD = Discriminator()\n",
        "target_netD = Discriminator()\n",
        "netD = netD.to(device)\n",
        "target_netD = target_netD.to(device)\n",
        "hard_update(target_netD, netD)\n",
        "\n",
        "optimizerD = Adam(netD.parameters(), lr=3e-4, betas=(0.5, 0.999))\n",
        "def cal_gradient_penalty(netD, real_data, fake_data, batch_size):\n",
        "    alpha = torch.rand(batch_size, 1)\n",
        "    alpha = alpha.expand(batch_size, int(real_data.nelement()/batch_size)).contiguous()\n",
        "    alpha = alpha.view(batch_size, 6, dim, dim)\n",
        "    alpha = alpha.to(device)\n",
        "    fake_data = fake_data.view(batch_size, 6, dim, dim)\n",
        "    interpolates = Variable(alpha * real_data.data + ((1 - alpha) * fake_data.data), requires_grad=True)\n",
        "    disc_interpolates = netD(interpolates)\n",
        "    gradients = autograd.grad(disc_interpolates, interpolates,\n",
        "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
        "                              create_graph=True, retain_graph=True)[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
        "    return gradient_penalty\n",
        "\n",
        "def cal_reward(fake_data, real_data):\n",
        "    return target_netD(torch.cat([real_data, fake_data], 1))\n",
        "\n",
        "def save_gan(path):\n",
        "    netD.cpu()\n",
        "    torch.save(netD.state_dict(),'{}/wgan.pkl'.format(path))\n",
        "    netD.to(device)\n",
        "\n",
        "def load_gan(path):\n",
        "    netD.load_state_dict(torch.load('{}/wgan.pkl'.format(path)))\n",
        "\n",
        "def update(fake_data, real_data): # update(canvas, gt)分辨画布和目标的区别\n",
        "    fake_data = fake_data.detach()\n",
        "    real_data = real_data.detach()\n",
        "    fake = torch.cat([real_data, fake_data], 1)\n",
        "    real = torch.cat([real_data, real_data], 1)\n",
        "    D_real = netD(real) #real & fake 分别过discriminator得到一个值\n",
        "    D_fake = netD(fake)\n",
        "    gradient_penalty = cal_gradient_penalty(netD, real, fake, real.shape[0])\n",
        "    optimizerD.zero_grad()\n",
        "    D_cost = D_fake.mean() - D_real.mean() + gradient_penalty\n",
        "    #discriminator的损失函数的负数，即原来越大越好，现在越小越好\n",
        "    D_cost.backward()\n",
        "    optimizerD.step()\n",
        "    soft_update(target_netD, netD, 0.001)\n",
        "    return D_fake.mean(), D_real.mean(), gradient_penalty\n"
      ],
      "metadata": {
        "id": "SI41rCmVDdOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DDPG**"
      ],
      "metadata": {
        "id": "CJpOkejSNN-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ddpg\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "coord = torch.zeros([1, 2, 128, 128])\n",
        "for i in range(128):\n",
        "    for j in range(128):\n",
        "        coord[0, 0, i, j] = i / 127.\n",
        "        coord[0, 1, i, j] = j / 127.\n",
        "coord = coord.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "Decoder = FCN() #renderer的网络模型，参数来自于renderer 改变渲染器类型以改变效果\n",
        "Decoder.load_state_dict(torch.load('../renderer.pkl'))\n",
        "\n",
        "#把笔画参数渲染到画布上去\n",
        "def decode(x, canvas): # b * (10 + 3) x相当于action\n",
        "    x = x.view(-1, 10 + 3)\n",
        "    stroke = 1 - Decoder(x[:, :10]) #笔画参数除颜色外\n",
        "    #在卷积之前，需要将图像边界填充1。笔划是白色还是黑色对解码器生成的图像边界影响较小。\n",
        "    stroke = stroke.view(-1, 128, 128, 1) #bsz x 128 x 128 x 1\n",
        "    color_stroke = stroke * x[:, -3:].view(-1, 1, 1, 3) #颜色笔刷\n",
        "    stroke = stroke.permute(0, 3, 1, 2) #permute置换维度 b x1x128x128\n",
        "    color_stroke = color_stroke.permute(0, 3, 1, 2)  # b x3x1x1\n",
        "    stroke = stroke.view(-1, 5, 1, 128, 128) #5是一笔下去的数目\n",
        "    color_stroke = color_stroke.view(-1, 5, 3, 128, 128)\n",
        "    for i in range(5): #一下画5笔\n",
        "        canvas = canvas * (1 - stroke[:, i]) + color_stroke[:, i]\n",
        "        #添加笔画不会直接覆盖一个区域。假设stroke的值为0.5，将一个面积乘以0.5，再加上color_stroke，就是添加一个透明度为50的stroke\n",
        "        #The stroke is not a 01 mask, the stroke is translucent. So you need to mix two parts.\n",
        "    return canvas\n",
        "\n",
        "def cal_trans(s, t):\n",
        "    return (s.transpose(0, 3) * t).transpose(0, 3)\n",
        "\n",
        "class DDPG(object):\n",
        "    def __init__(self, batch_size=64, env_batch=1, max_step=40, \\\n",
        "                 tau=0.001, discount=0.9, rmsize=800, \\\n",
        "                 writer=None, resume=None, output_path=None):\n",
        "      #env_batch=96 discount=0。9**5 这两个和trian不一样\n",
        "\n",
        "        self.max_step = max_step\n",
        "        self.env_batch = env_batch\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.actor = ResNet(9, 18, 65) # target, canvas, stepnum, coordconv 3 + 3 + 1 + 2\n",
        "        #ResNet(num_inputs, depth, num_outputs)\n",
        "        self.actor_target = ResNet(9, 18, 65)\n",
        "        self.critic = ResNet_wobn(3 + 9, 18, 1) # add the last canvas for better prediction\n",
        "        self.critic_target = ResNet_wobn(3 + 9, 18, 1)\n",
        "\n",
        "        self.actor_optim  = Adam(self.actor.parameters(), lr=1e-2)\n",
        "        self.critic_optim  = Adam(self.critic.parameters(), lr=1e-2)\n",
        "\n",
        "        if (resume != None):\n",
        "            self.load_weights(resume) #加载之前保存的数据\n",
        "\n",
        "        #hard_update为了让参数一致\n",
        "        hard_update(self.actor_target, self.actor)\n",
        "        hard_update(self.critic_target, self.critic)\n",
        "\n",
        "        # Create replay buffer\n",
        "        self.memory = rpm(rmsize * max_step)\n",
        "\n",
        "        # Hyper-parameters\n",
        "        self.tau = tau\n",
        "        self.discount = discount\n",
        "\n",
        "        # Tensorboard\n",
        "        self.writer = writer\n",
        "        self.log = 0\n",
        "\n",
        "        self.state = [None] * self.env_batch # Most recent state\n",
        "        self.action = [None] * self.env_batch # Most recent action\n",
        "        self.choose_device()\n",
        "\n",
        "    def play(self, state, target=False):\n",
        "    # S=(Ct,I,t) 按照actor网络动作\n",
        "        state = torch.cat((state[:, :6].float() / 255, state[:, 6:7].float() / self.max_step, coord.expand(state.shape[0], 2, 128, 128)), 1)\n",
        "        if target:\n",
        "            return self.actor_target(state)\n",
        "        else:\n",
        "            return self.actor(state)\n",
        "\n",
        "    def update_gan(self, state): #更新了Discriminator\n",
        "        canvas = state[:, :3]\n",
        "        gt = state[:, 3 : 6]\n",
        "        fake, real, penal = update(canvas.float() / 255, gt.float() / 255)\n",
        "        #disciminator返回的评价像不像（conditional两个指标）\n",
        "        if self.log % 20 == 0:\n",
        "            self.writer.add_scalar('train/gan_fake', fake, self.log)\n",
        "            self.writer.add_scalar('train/gan_real', real, self.log)\n",
        "            self.writer.add_scalar('train/gan_penal', penal, self.log)\n",
        "\n",
        "    def evaluate(self, state, action, target=False):\n",
        "    #target_q, _ = self.evaluate(Si+1，target_actor（Si+1），True)\n",
        "    #整个还是相当于Q（s,a），因为输入的是s+a，但是具体里面操作的时候用s和s后面一个状态。\n",
        "    #我觉得可以理解成（ri+1）+V（si+2）\n",
        "        T = state[:, 6 : 7]\n",
        "        gt = state[:, 3 : 6].float() / 255\n",
        "        canvas0 = state[:, :3].float() / 255\n",
        "        canvas1 = decode(action, canvas0) #返回的是画过五笔的canvas\n",
        "        gan_reward = cal_reward(canvas1, gt) - cal_reward(canvas0, gt)\n",
        "        # （ri+1） rt = Lt-Lt+1 由target_D给出\n",
        "        # L2_reward = ((canvas0 - gt) ** 2).mean(1).mean(1).mean(1) - ((canvas1 - gt) ** 2).mean(1).mean(1).mean(1)\n",
        "        coord_ = coord.expand(state.shape[0], 2, 128, 128) #加入坐标点\n",
        "        merged_state = torch.cat([canvas0, canvas1, gt, (T + 1).float() / self.max_step, coord_], 1)\n",
        "        # 融合状态 canvas0 is not necessarily added\n",
        "        if target:\n",
        "            Q = self.critic_target(merged_state)\n",
        "            return (Q + gan_reward), gan_reward\n",
        "        else:\n",
        "            Q = self.critic(merged_state)\n",
        "            if self.log % 20 == 0:\n",
        "                self.writer.add_scalar('train/expect_reward', Q.mean(), self.log)\n",
        "                self.writer.add_scalar('train/gan_reward', gan_reward.mean(), self.log)\n",
        "            return (Q + gan_reward), gan_reward\n",
        "\n",
        "    def update_policy(self, lr): #更新策略\n",
        "        self.log += 1\n",
        "\n",
        "        for param_group in self.critic_optim.param_groups:\n",
        "            param_group['lr'] = lr[0]\n",
        "        for param_group in self.actor_optim.param_groups:\n",
        "            param_group['lr'] = lr[1]\n",
        "\n",
        "        # Sample batch 从buffer里面采样一堆，terminal---done\n",
        "        state, action, reward, \\\n",
        "            next_state, terminal = self.memory.sample_batch(self.batch_size, device)\n",
        "\n",
        "        self.update_gan(next_state)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            next_action = self.play(next_state, True)\n",
        "            target_q, _ = self.evaluate(next_state, next_action, True)\n",
        "            #这个evaluate是DDPG里面的   Si+1，target_actor（Si+1）\n",
        "            target_q = self.discount * ((1 - terminal.float()).view(-1, 1)) * target_q\n",
        "\n",
        "        cur_q, step_reward = self.evaluate(state, action)\n",
        "        target_q += step_reward.detach()\n",
        "        #t_Q(s1,t_c(s1))+r0=Q(s0,a0) 用value_loss更新critic\n",
        "        value_loss = criterion(cur_q, target_q)\n",
        "        self.critic.zero_grad()\n",
        "        value_loss.backward(retain_graph=True)\n",
        "        self.critic_optim.step()\n",
        "\n",
        "        action = self.play(state)\n",
        "        pre_q, _ = self.evaluate(state.detach(), action)\n",
        "        policy_loss = -pre_q.mean() #让pre_q越大越好\n",
        "        self.actor.zero_grad()\n",
        "        policy_loss.backward(retain_graph=True)\n",
        "        self.actor_optim.step()#更新actor\n",
        "\n",
        "        # Target update\n",
        "        # 软更新可能是为了让参数不要变得那么剧烈\n",
        "        soft_update(self.actor_target, self.actor, self.tau)\n",
        "        soft_update(self.critic_target, self.critic, self.tau)\n",
        "\n",
        "        return -policy_loss, value_loss\n",
        "\n",
        "    def observe(self, reward, state, done, step):\n",
        "    #把数据存进replay buffer里面,observation~state~St+1\n",
        "        s0 = torch.tensor(self.state, device='cpu')\n",
        "        a = to_tensor(self.action, \"cpu\")\n",
        "        r = to_tensor(reward, \"cpu\")\n",
        "        s1 = torch.tensor(state, device='cpu')\n",
        "        #s0与s1的差别在于self\n",
        "        d = to_tensor(done.astype('float32'), \"cpu\")\n",
        "        for i in range(self.env_batch):\n",
        "            self.memory.append([s0[i], a[i], r[i], s1[i], d[i]])\n",
        "        self.state = state #把新状态换上\n",
        "\n",
        "    def noise_action(self, noise_factor, state, action): #增加随机性？？\n",
        "        noise = np.zeros(action.shape)\n",
        "        for i in range(self.env_batch):\n",
        "            action[i] = action[i] + np.random.normal(0, self.noise_level[i], action.shape[1:]).astype('float32')\n",
        "        return np.clip(action.astype('float32'), 0, 1)\n",
        "    def select_action(self, state, return_fix=False, noise_factor=0):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            action = self.play(state)\n",
        "            action = to_numpy(action)\n",
        "        if noise_factor > 0:\n",
        "            action = self.noise_action(noise_factor, state, action)\n",
        "        self.train() #把模式改为训练\n",
        "        self.action = action\n",
        "        if return_fix:\n",
        "            return action\n",
        "        return self.action\n",
        "\n",
        "    def reset(self, obs, factor):\n",
        "        self.state = obs #obs在env里面=state在agent里面，相当于agent吃进来obs\n",
        "        self.noise_level = np.random.uniform(0, factor, self.env_batch)\n",
        "\n",
        "    def load_weights(self, path):\n",
        "        if path is None: return\n",
        "        self.actor.load_state_dict(torch.load('{}/actor.pkl'.format(path)))\n",
        "        self.critic.load_state_dict(torch.load('{}/critic.pkl'.format(path)))\n",
        "        load_gan(path)\n",
        "\n",
        "    def save_model(self, path):\n",
        "        self.actor.cpu()\n",
        "        self.critic.cpu()\n",
        "        torch.save(self.actor.state_dict(),'{}/actor.pkl'.format(path))\n",
        "        torch.save(self.critic.state_dict(),'{}/critic.pkl'.format(path))\n",
        "        save_gan(path)\n",
        "        self.choose_device()\n",
        "\n",
        "    def eval(self):\n",
        "        self.actor.eval()\n",
        "        self.actor_target.eval()\n",
        "        self.critic.eval()\n",
        "        self.critic_target.eval()\n",
        "\n",
        "    def train(self):\n",
        "        self.actor.train()\n",
        "        self.actor_target.train()\n",
        "        self.critic.train()\n",
        "        self.critic_target.train()\n",
        "\n",
        "    def choose_device(self):\n",
        "        Decoder.to(device)\n",
        "        self.actor.to(device)\n",
        "        self.actor_target.to(device)\n",
        "        self.critic.to(device)\n",
        "        self.critic_target.to(device)\n"
      ],
      "metadata": {
        "id": "KkFC_DEtCcn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train_renderer**\n",
        "预先训练好神经渲染器"
      ],
      "metadata": {
        "id": "lmoXw8EkJOLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = TensorBoard(\"../train_log/\") #写日志\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.MSELoss() #MSE均方根\n",
        "net = FCN() #模型是renderer设置好的模型，subpixel convolution\n",
        "'''FCN is a network that does not contain any “Dense” layers\n",
        "(as in traditional CNNs) instead it contains 1x1 convolutions\n",
        "that perform the task of fully connected layers (Dense layers).\n",
        "'''\n",
        "optimizer = optim.Adam(net.parameters(), lr=3e-6) #adam优化方法\n",
        "batch_size = 64\n",
        "\n",
        "use_cuda = torch.cuda.is_available() #cuda能使用则use_cuda=1;反之\n",
        "step = 0 #循环计数\n",
        "\n",
        "\n",
        "def save_model():\n",
        "    if use_cuda:\n",
        "        net.cpu()\n",
        "    torch.save(net.state_dict(), \"../renderer.pkl\")\n",
        "    if use_cuda:\n",
        "        net.cuda()\n",
        "\n",
        "\n",
        "def load_weights():\n",
        "    pretrained_dict = torch.load(\"../renderer.pkl\")\n",
        "    model_dict = net.state_dict()\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    net.load_state_dict(model_dict)\n",
        "\n",
        "\n",
        "#load_weights()\n",
        "while step < 500000: #循环五十万次500000\n",
        "    net.train()   #模型训练模式\n",
        "    train_batch = []\n",
        "    ground_truth = []\n",
        "    for i in range(batch_size):  #batchsize里面的循环64次\n",
        "        f = np.random.uniform(0, 1, 10) #从一个均匀分布[low,high)中随机采样，[0,1)采样10个数\n",
        "        train_batch.append(f)\n",
        "        ground_truth.append(draw(f)) #ground_truth里面是用draw(f)渲染的笔画，cv2里面的\n",
        "\n",
        "    train_batch = torch.tensor(train_batch).float()\n",
        "    ground_truth = torch.tensor(ground_truth).float()\n",
        "    if use_cuda:\n",
        "        net = net.cuda()\n",
        "        train_batch = train_batch.cuda()\n",
        "        ground_truth = ground_truth.cuda()\n",
        "    gen = net(train_batch)\n",
        "    #train_batch里面都是随机生成的f，gen是一个神经网络\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(gen, ground_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(step, loss.item())\n",
        "    #以上为网络参数优化，使得神经渲染器画出的效果和draw差不多\n",
        "    #以下为调整学习率，这好粗暴呀\n",
        "    if step < 200000:\n",
        "        lr = 1e-4\n",
        "    elif step < 400000:\n",
        "        lr = 1e-5\n",
        "    else:\n",
        "        lr = 1e-6\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "    writer.add_scalar(\"train/loss\", loss.item(), step)\n",
        "    #每一百步就验证一下\n",
        "    if step % 100 == 0:\n",
        "        net.eval()\n",
        "        gen = net(train_batch)\n",
        "        loss = criterion(gen, ground_truth)\n",
        "        writer.add_scalar(\"val/loss\", loss.item(), step)\n",
        "        for i in range(32):\n",
        "            G = gen[i].cpu().data.numpy()\n",
        "            GT = ground_truth[i].cpu().data.numpy()\n",
        "            writer.add_image(\"train/gen{}.png\".format(i), G, step)\n",
        "            writer.add_image(\"train/ground_truth{}.png\".format(i), GT, step)\n",
        "    #每一千次就保存模型\n",
        "    if step % 1000 == 0:\n",
        "        save_model()\n",
        "    step += 1\n"
      ],
      "metadata": {
        "id": "4QUXKnN4Ed8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnGxG7IwuDHb",
        "outputId": "9eddd6b3-492b-4ce4-c8ea-4462bedafe73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/essay/LearningToPaint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir train_log --port=6006 #查看日志"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt3em4tGt9ty",
        "outputId": "81deaf8e-0cdf-4889-ba5e-71a7fd877778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.8.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Environment/Paint**"
      ],
      "metadata": {
        "id": "jbXpfBoAxaz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #%%writefile baseline/env.py\n",
        " #功能是将笔画参数at转化成状态st+1，给出奖励\n",
        "import json\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "aug = transforms.Compose(\n",
        "            [transforms.ToPILImage(),\n",
        "             transforms.RandomHorizontalFlip(),\n",
        "             ])\n",
        "#一般用Compose把多个步骤整合到一起，转成PIL图像，以0.5的概率水平翻转给定的PIL图像\n",
        "\n",
        "width = 128\n",
        "convas_area = width * width #画布大小\n",
        "\n",
        "img_train = []\n",
        "img_test = []\n",
        "train_num = 0\n",
        "test_num = 0\n",
        "\n",
        "class Paint:\n",
        "    def __init__(self, batch_size, max_step):\n",
        "        self.batch_size = batch_size\n",
        "        self.max_step = max_step\n",
        "        self.action_space = (13)\n",
        "        self.observation_space = (self.batch_size, width, width, 7)\n",
        "        self.test = False\n",
        "\n",
        "    def load_data(self):\n",
        "        # CelebA 二十万张照片\n",
        "        global train_num, test_num\n",
        "        for i in range(200000):\n",
        "            img_id = '%06d' % (i + 1)\n",
        "            try:\n",
        "                img = cv2.imread('./data/img_align_celeba/' + img_id + '.jpg', cv2.IMREAD_UNCHANGED)\n",
        "                img = cv2.resize(img, (width, width))\n",
        "                if i > 2000:\n",
        "                    train_num += 1\n",
        "                    img_train.append(img)\n",
        "                else:\n",
        "                    test_num += 1\n",
        "                    img_test.append(img)\n",
        "            finally:\n",
        "                if (i + 1) % 10000 == 0:\n",
        "                    print('loaded {} images'.format(i + 1))\n",
        "        #2000张图片做test？？\n",
        "        print('finish loading data, {} training images, {} testing images'.format(str(train_num), str(test_num)))\n",
        "\n",
        "    def pre_data(self, id, test):\n",
        "        if test:\n",
        "            img = img_test[id]\n",
        "        else:\n",
        "            img = img_train[id]\n",
        "        if not test: #train的数据增广\n",
        "            img = aug(img)\n",
        "        img = np.asarray(img)\n",
        "        return np.transpose(img, (2, 0, 1)) #转置\n",
        "\n",
        "    def reset(self, test=False, begin_num=False): #一张图训练完成之后重置???\n",
        "        self.test = test\n",
        "        self.imgid = [0] * self.batch_size\n",
        "        self.gt = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
        "        #目标和id清零\n",
        "        for i in range(self.batch_size): #？？一次性并行画几幅画\n",
        "            if test:\n",
        "                id = (i + begin_num)  % test_num\n",
        "            else:\n",
        "                id = np.random.randint(train_num) #返回从低（包括）到高（不包括）的随机整数\n",
        "            self.imgid[i] = id\n",
        "            self.gt[i] = torch.tensor(self.pre_data(id, test))\n",
        "        self.tot_reward = ((self.gt.float() / 255) ** 2).mean(1).mean(1).mean(1)\n",
        "        self.stepnum = 0\n",
        "        self.canvas = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
        "        #canvas是一个张量空间\n",
        "        self.lastdis = self.ini_dis = self.cal_dis()\n",
        "        return self.observation()\n",
        "\n",
        "    def observation(self): #其实就是state=(C,I,T)\n",
        "        # canvas B * 3 * width * width\n",
        "        # gt B * 3 * width * width\n",
        "        # T B * 1 * width * width\n",
        "        ob = []\n",
        "        T = torch.ones([self.batch_size, 1, width, width], dtype=torch.uint8) * self.stepnum\n",
        "        return torch.cat((self.canvas, self.gt, T.to(device)), 1) # canvas, img, T\n",
        "\n",
        "    def cal_trans(self, s, t):\n",
        "        return (s.transpose(0, 3) * t).transpose(0, 3)\n",
        "\n",
        "    def step(self, action): #返回下一个state、reward以及是否完成episode\n",
        "        self.canvas = (decode(action, self.canvas.float() / 255) * 255).byte() #decode相当于渲染器一样\n",
        "        self.stepnum += 1\n",
        "        ob = self.observation()\n",
        "        done = (self.stepnum == self.max_step)\n",
        "        reward = self.cal_reward() # np.array([0.] * self.batch_size)\n",
        "        return ob.detach(), reward, np.array([done] * self.batch_size), None\n",
        "        #detach---Returns a new Tensor, detached from the current graph.\n",
        "\n",
        "    def cal_dis(self):\n",
        "    #计算距离，这是L2distance\n",
        "        return (((self.canvas.float() - self.gt.float()) / 255) ** 2).mean(1).mean(1).mean(1)\n",
        "\n",
        "    def cal_reward(self):\n",
        "    #计算reward Lt-（Lt+1）\n",
        "        dis = self.cal_dis()\n",
        "        reward = (self.lastdis - dis) / (self.ini_dis + 1e-8)\n",
        "        self.lastdis = dis\n",
        "        return to_numpy(reward)"
      ],
      "metadata": {
        "id": "hWTO7--lEiz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multi 并行环境\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class fastenv():\n",
        "    def __init__(self,\n",
        "                 max_episode_length=10, env_batch=64, \\\n",
        "                 writer=None):\n",
        "        self.max_episode_length = max_episode_length\n",
        "        self.env_batch = env_batch\n",
        "        self.env = Paint(self.env_batch, self.max_episode_length) #定义了env=paint\n",
        "                  #并行环境数目，每个episode中最大长度\n",
        "        self.env.load_data()\n",
        "        self.observation_space = self.env.observation_space\n",
        "        self.action_space = self.env.action_space\n",
        "        self.writer = writer\n",
        "        self.test = False\n",
        "        self.log = 0\n",
        "\n",
        "    def save_image(self, log, step):\n",
        "        for i in range(self.env_batch):\n",
        "            if self.env.imgid[i] <= 10:\n",
        "                canvas = cv2.cvtColor((to_numpy(self.env.canvas[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n",
        "                self.writer.add_image('{}/canvas_{}.png'.format(str(self.env.imgid[i]), str(step)), canvas, log)\n",
        "        if step == self.max_episode_length:\n",
        "            for i in range(self.env_batch):\n",
        "                if self.env.imgid[i] < 50:\n",
        "                    gt = cv2.cvtColor((to_numpy(self.env.gt[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n",
        "                    canvas = cv2.cvtColor((to_numpy(self.env.canvas[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n",
        "                    self.writer.add_image(str(self.env.imgid[i]) + '/_target.png', gt, log)\n",
        "                    self.writer.add_image(str(self.env.imgid[i]) + '/_canvas.png', canvas, log)\n",
        "\n",
        "    def step(self, action):\n",
        "        with torch.no_grad():\n",
        "            ob, r, d, _ = self.env.step(torch.tensor(action).to(device))\n",
        "        if d[0]:\n",
        "            if not self.test:\n",
        "                self.dist = self.get_dist()\n",
        "                for i in range(self.env_batch):\n",
        "                    self.writer.add_scalar('train/dist', self.dist[i], self.log)\n",
        "                    self.log += 1\n",
        "        return ob, r, d, _\n",
        "\n",
        "    def get_dist(self): #类似env里面的cal_dis，计算画布和目标的L2距离\n",
        "        return to_numpy((((self.env.gt.float() - self.env.canvas.float()) / 255) ** 2).mean(1).mean(1).mean(1))\n",
        "\n",
        "    def reset(self, test=False, episode=0):\n",
        "        self.test = test\n",
        "        ob = self.env.reset(self.test, episode * self.env_batch)\n",
        "        return ob"
      ],
      "metadata": {
        "id": "ApzR3FSjC7qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train**"
      ],
      "metadata": {
        "id": "skAGPEmv67pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 baseline/train.py --max_step=200 --debug --batch_size=96"
      ],
      "metadata": {
        "id": "1m90-H06Em7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "exp = os.path.abspath('.').split('/')[-1]\n",
        "writer = TensorBoard('../train_log/{}'.format(exp))\n",
        "os.system('ln -sf ../train_log/{} ./log'.format(exp))\n",
        "os.system('mkdir ./model')\n",
        "\n",
        "#代码入口在此\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='Learning to Paint') # hyper-parameter 超参数\n",
        "    parser.add_argument('--warmup', default=400, type=int, help='timestep without training but only filling the replay memory')\n",
        "    #warmup 将数据填充repaly buffer\n",
        "    parser.add_argument('--discount', default=0.95**5, type=float, help='discount factor')\n",
        "    parser.add_argument('--batch_size', default=96, type=int, help='minibatch size')\n",
        "    parser.add_argument('--rmsize', default=800, type=int, help='replay memory size')\n",
        "    parser.add_argument('--env_batch', default=96, type=int, help='concurrent environment number')\n",
        "    #env_batch 并行环境的数目\n",
        "    parser.add_argument('--tau', default=0.001, type=float, help='moving average for target network')\n",
        "    #tau目标网络参数相关\n",
        "    parser.add_argument('--max_step', default=40, type=int, help='max length for episode')\n",
        "    #max_step 一个episode的最大长度\n",
        "    parser.add_argument('--noise_factor', default=0, type=float, help='noise level for parameter space noise')\n",
        "    parser.add_argument('--validate_interval', default=50, type=int, help='how many episodes to perform a validation')\n",
        "    #隔多少episode才来一次valid\n",
        "    parser.add_argument('--validate_episodes', default=5, type=int, help='how many episode to perform during validation')\n",
        "    #validation里面有多少episode\n",
        "    parser.add_argument('--train_times', default=2000000, type=int, help='total traintimes')\n",
        "    #train_times means model the number of update iterations during training.\n",
        "    parser.add_argument('--episode_train_times', default=10, type=int, help='train times for each episode')\n",
        "    #episode_train_times means the number of model update iterations after every batch of finished episode.\n",
        "    #episode_train_times 一个episode中训练几次\n",
        "    parser.add_argument('--resume', default=None, type=str, help='Resuming model path for testing')\n",
        "    #resume 重新恢复模型路径\n",
        "    parser.add_argument('--output', default='./model', type=str, help='Resuming model path for testing')\n",
        "    parser.add_argument('--debug', dest='debug', action='store_true', help='print some info')\n",
        "    parser.add_argument('--seed', default=1234, type=int, help='random seed')\n",
        "    args = parser.parse_args()\n",
        "    args.output = get_output_folder(args.output, \"Paint\")#参数parent_dir, env_name\n",
        "\n",
        "    #设置随机数种子\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(args.seed)\n",
        "    random.seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    #设置并行env a episodde max steo=40 96个不同图像并行\n",
        "    fenv = fastenv(args.max_step, args.env_batch, writer)\n",
        "    agent = DDPG(args.batch_size, args.env_batch, args.max_step, \\\n",
        "                 args.tau, args.discount, args.rmsize, \\\n",
        "                 writer, args.resume, args.output)\n",
        "    evaluate = Evaluator(args, writer) #验证的时候使用\n",
        "    print('observation_space', fenv.observation_space, 'action_space', fenv.action_space)\n",
        "    train(agent, fenv, evaluate)\n",
        "\n",
        "def train(agent, env, evaluate):\n",
        "    train_times = args.train_times\n",
        "    env_batch = args.env_batch\n",
        "    validate_interval = args.validate_interval\n",
        "    max_step = args.max_step\n",
        "    debug = args.debug\n",
        "    episode_train_times = args.episode_train_times\n",
        "    resume = args.resume\n",
        "    output = args.output\n",
        "    time_stamp = time.time() #时间戳，记录时间\n",
        "    step = episode = episode_steps = 0\n",
        "    # 训练次数计数，画多少幅画计数，在一幅画里有多少步计数\n",
        "    tot_reward = 0.\n",
        "    observation = None\n",
        "    noise_factor = args.noise_factor\n",
        "    while step <= train_times: #两百万次训练\n",
        "        step += 1\n",
        "        episode_steps += 1\n",
        "        # reset if it is the start of episode\n",
        "        if observation is None:\n",
        "            observation = env.reset()\n",
        "            agent.reset(observation, noise_factor)\n",
        "        action = agent.select_action(observation, noise_factor=noise_factor)\n",
        "        observation, reward, done, _ = env.step(action)\n",
        "        agent.observe(reward, observation, done, step)\n",
        "        #agent就是DDPG（在程序里面），把这些数据存起来observe\n",
        "        if (episode_steps >= max_step and max_step): #经过了一个episode，即40次画出了一幅画\n",
        "            if step > args.warmup: #warmup=400\n",
        "                # [optional] evaluate 验证集上的事情\n",
        "                if episode > 0 and validate_interval > 0 and episode % validate_interval == 0:\n",
        "                    reward, dist = evaluate(env, agent.select_action, debug=debug)\n",
        "                    #evaluate相当于evaluator，计算平均收益、距离的平均和方差\n",
        "                    if debug: prRed('Step_{:07d}: mean_reward:{:.3f} mean_dist:{:.3f} var_dist:{:.3f}'.format(step - 1, np.mean(reward), np.mean(dist), np.var(dist)))\n",
        "                    writer.add_scalar('validate/mean_reward', np.mean(reward), step)\n",
        "                    writer.add_scalar('validate/mean_dist', np.mean(dist), step)\n",
        "                    writer.add_scalar('validate/var_dist', np.var(dist), step)\n",
        "                    agent.save_model(output)\n",
        "            train_time_interval = time.time() - time_stamp #时间间隔\n",
        "            time_stamp = time.time()\n",
        "            tot_Q = 0. # Q(s,a)\n",
        "            tot_value_loss = 0.\n",
        "            if step > args.warmup:\n",
        "                if step < 10000 * max_step:\n",
        "                    lr = (3e-4, 1e-3)\n",
        "                elif step < 20000 * max_step:\n",
        "                    lr = (1e-4, 3e-4)\n",
        "                else:\n",
        "                    lr = (3e-5, 1e-4)\n",
        "                #随着训练的episode的增加，改变学习率(critic & actor)\n",
        "                for i in range(episode_train_times): #在一个episode里面更新10次参数\n",
        "                    Q, value_loss = agent.update_policy(lr)\n",
        "                    tot_Q += Q.data.cpu().numpy()\n",
        "                    tot_value_loss += value_loss.data.cpu().numpy()\n",
        "                writer.add_scalar('train/critic_lr', lr[0], step)\n",
        "                writer.add_scalar('train/actor_lr', lr[1], step)\n",
        "                writer.add_scalar('train/Q', tot_Q / episode_train_times, step)\n",
        "                writer.add_scalar('train/critic_loss', tot_value_loss / episode_train_times, step)\n",
        "            if debug: prBlack('#{}: steps:{} interval_time:{:.2f} train_time:{:.2f}' \\\n",
        "                .format(episode, step, train_time_interval, time.time()-time_stamp))\n",
        "            time_stamp = time.time()\n",
        "            # reset\n",
        "            observation = None\n",
        "            episode_steps = 0\n",
        "            episode += 1\n"
      ],
      "metadata": {
        "id": "95aa0t5CyDTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "3d083dc2-f8a8-4a35-cf25-b406ac20762c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--warmup WARMUP] [--discount DISCOUNT]\n",
            "                             [--batch_size BATCH_SIZE] [--rmsize RMSIZE]\n",
            "                             [--env_batch ENV_BATCH] [--tau TAU]\n",
            "                             [--max_step MAX_STEP]\n",
            "                             [--noise_factor NOISE_FACTOR]\n",
            "                             [--validate_interval VALIDATE_INTERVAL]\n",
            "                             [--validate_episodes VALIDATE_EPISODES]\n",
            "                             [--train_times TRAIN_TIMES]\n",
            "                             [--episode_train_times EPISODE_TRAIN_TIMES]\n",
            "                             [--resume RESUME] [--output OUTPUT] [--debug]\n",
            "                             [--seed SEED]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-f393c00a-2a62-47dd-9d42-6d90fd28f3a0.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test**"
      ],
      "metadata": {
        "id": "CVCH1OGJyFWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "width = 128\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Learning to Paint')\n",
        "parser.add_argument('--max_step', default=40, type=int, help='max length for episode')\n",
        "parser.add_argument('--actor', default='./model/Paint-run1/actor.pkl', type=str, help='Actor model')\n",
        "parser.add_argument('--renderer', default='./renderer.pkl', type=str, help='renderer model')\n",
        "#以上两个为保存的模型\n",
        "parser.add_argument('--img', default='image/test.png', type=str, help='test image')\n",
        "parser.add_argument('--imgid', default=0, type=int, help='set begin number for generated image')\n",
        "#imgid从零开始\n",
        "parser.add_argument('--divide', default=4, type=int, help='divide the target image to get better resolution')\n",
        "args = parser.parse_args()\n",
        "\n",
        "canvas_cnt = args.divide * args.divide # 4 * 4 = 16 画布计数器\n",
        "T = torch.ones([1, 1, width, width], dtype=torch.float32).to(device)\n",
        "img = cv2.imread(args.img, cv2.IMREAD_COLOR) #读入测试图片\n",
        "origin_shape = (img.shape[1], img.shape[0])\n",
        "\n",
        "coord = torch.zeros([1, 2, width, width])\n",
        "for i in range(width):\n",
        "    for j in range(width):\n",
        "        coord[0, 0, i, j] = i / (width - 1.)\n",
        "        coord[0, 1, i, j] = j / (width - 1.)\n",
        "coord = coord.to(device) # Coordconv\n",
        "\n",
        "Decoder = FCN() #渲染器\n",
        "Decoder.load_state_dict(torch.load(args.renderer))\n",
        "\n",
        "def decode(x, canvas): # b * (10 + 3)\n",
        "    x = x.view(-1, 10 + 3)\n",
        "    stroke = 1 - Decoder(x[:, :10])\n",
        "    stroke = stroke.view(-1, width, width, 1)\n",
        "    color_stroke = stroke * x[:, -3:].view(-1, 1, 1, 3)\n",
        "    stroke = stroke.permute(0, 3, 1, 2)\n",
        "    color_stroke = color_stroke.permute(0, 3, 1, 2)\n",
        "    stroke = stroke.view(-1, 5, 1, width, width)\n",
        "    color_stroke = color_stroke.view(-1, 5, 3, width, width)\n",
        "    res = []\n",
        "    for i in range(5):\n",
        "        canvas = canvas * (1 - stroke[:, i]) + color_stroke[:, i]\n",
        "        res.append(canvas)\n",
        "    return canvas, res #返回最终画布状态和累计状态\n",
        "\n",
        "#放大or缩小\n",
        "def small2large(x):\n",
        "    # (d * d, width, width) -> (d * width, d * width)\n",
        "    x = x.reshape(args.divide, args.divide, width, width, -1)\n",
        "    x = np.transpose(x, (0, 2, 1, 3, 4))\n",
        "    x = x.reshape(args.divide * width, args.divide * width, -1)\n",
        "    return x\n",
        "def large2small(x):\n",
        "    # (d * width, d * width) -> (d * d, width, width)\n",
        "    x = x.reshape(args.divide, width, args.divide, width, 3)\n",
        "    x = np.transpose(x, (0, 2, 1, 3, 4))\n",
        "    x = x.reshape(canvas_cnt, width, width, 3)\n",
        "    return x\n",
        "\n",
        "def smooth(img): #平滑画面我感觉是\n",
        "    def smooth_pix(img, tx, ty):\n",
        "        if tx == args.divide * width - 1 or ty == args.divide * width - 1 or tx == 0 or ty == 0:\n",
        "            return img\n",
        "        img[tx, ty] = (img[tx, ty] + img[tx + 1, ty] + img[tx, ty + 1] + img[tx - 1, ty] + img[tx, ty - 1] + img[tx + 1, ty - 1] + img[tx - 1, ty + 1] + img[tx - 1, ty - 1] + img[tx + 1, ty + 1]) / 9\n",
        "        return img\n",
        "\n",
        "    for p in range(args.divide):\n",
        "        for q in range(args.divide):\n",
        "            x = p * width\n",
        "            y = q * width\n",
        "            for k in range(width):\n",
        "                img = smooth_pix(img, x + k, y + width - 1)\n",
        "                if q != args.divide - 1:\n",
        "                    img = smooth_pix(img, x + k, y + width)\n",
        "            for k in range(width):\n",
        "                img = smooth_pix(img, x + width - 1, y + k)\n",
        "                if p != args.divide - 1:\n",
        "                    img = smooth_pix(img, x + width, y + k)\n",
        "    return img\n",
        "\n",
        "def save_img(res, imgid, divide=False):\n",
        "    output = res.detach().cpu().numpy() # d * d, 3, width, width\n",
        "    output = np.transpose(output, (0, 2, 3, 1))\n",
        "    if divide:\n",
        "        output = small2large(output)\n",
        "        output = smooth(output)\n",
        "    else:\n",
        "        output = output[0]\n",
        "    output = (output * 255).astype('uint8')\n",
        "    output = cv2.resize(output, origin_shape)\n",
        "    cv2.imwrite('output/generated' + str(imgid) + '.png', output)\n",
        "\n",
        "actor = ResNet(9, 18, 65) # action_bundle = 5, 65 = 5 * 13\n",
        "actor.load_state_dict(torch.load(args.actor))\n",
        "actor = actor.to(device).eval()\n",
        "Decoder = Decoder.to(device).eval()\n",
        "\n",
        "canvas = torch.zeros([1, 3, width, width]).to(device) # 初始为空白画布\n",
        "\n",
        "patch_img = cv2.resize(img, (width * args.divide, width * args.divide))\n",
        "patch_img = large2small(patch_img)\n",
        "patch_img = np.transpose(patch_img, (0, 3, 1, 2))\n",
        "patch_img = torch.tensor(patch_img).to(device).float() / 255.\n",
        "\n",
        "img = cv2.resize(img, (width, width))\n",
        "img = img.reshape(1, width, width, 3)\n",
        "img = np.transpose(img, (0, 3, 1, 2))\n",
        "img = torch.tensor(img).to(device).float() / 255.\n",
        "\n",
        "os.system('mkdir output')\n",
        "#一个是整个图片画画，一个是把图片分成16份画画\n",
        "with torch.no_grad():\n",
        "    if args.divide != 1:\n",
        "        args.max_step = args.max_step // 2 # max_step=40\n",
        "    for i in range(args.max_step):\n",
        "        stepnum = T * i / args.max_step\n",
        "        actions = actor(torch.cat([canvas, img, stepnum, coord], 1))\n",
        "        canvas, res = decode(actions, canvas) #res记录画布状态\n",
        "        print('canvas step {}, L2Loss = {}'.format(i, ((canvas - img) ** 2).mean()))\n",
        "        for j in range(5):\n",
        "            save_img(res[j], args.imgid)\n",
        "            #save_img(color_stroke[:,i], args.imgid)\n",
        "            args.imgid += 1\n",
        "    if args.divide != 1:\n",
        "        #把画布调整成和目标图像一样\n",
        "        canvas = canvas[0].detach().cpu().numpy()\n",
        "        canvas = np.transpose(canvas, (1, 2, 0))\n",
        "        canvas = cv2.resize(canvas, (width * args.divide, width * args.divide))\n",
        "        canvas = large2small(canvas)\n",
        "        canvas = np.transpose(canvas, (0, 3, 1, 2))\n",
        "        canvas = torch.tensor(canvas).to(device).float()\n",
        "        coord = coord.expand(canvas_cnt, 2, width, width)\n",
        "        T = T.expand(canvas_cnt, 1, width, width) #拓展向量\n",
        "        for i in range(args.max_step):\n",
        "            stepnum = T * i / args.max_step\n",
        "            actions = actor(torch.cat([canvas, patch_img, stepnum, coord], 1))\n",
        "            canvas, res = decode(actions, canvas)\n",
        "            print('divided canvas step {}, L2Loss = {}'.format(i, ((canvas - patch_img) ** 2).mean()))\n",
        "            for j in range(5):\n",
        "                save_img(res[j], args.imgid, True)\n",
        "                args.imgid += 1\n"
      ],
      "metadata": {
        "id": "j3dJ3CbhEDgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}